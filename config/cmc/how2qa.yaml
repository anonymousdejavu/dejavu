name: cmc
try_name: how2qa
dataset: how2qa
base_model_name: openai/clip-vit-large-patch14
fps: 2
batch_size: 18
num_frames: 5
use_cos_sim_loss: true
use_fixed_pattern: true
ref_type: p4_p2n2_p1n1
lr_patience: 15
patience: 30

# Optimizer
restoration_lr: 0.0001
blobnet_lr: 0.02
decision_lr: 0.01

# Dataset
frame_stack_pattern: [0]
use_coded_order: false
disable_mask: true

# Decision Module
decision_type: 'threshold'
decision_hyperparam: -170
disable_final_tanh: true

# Gating Module
gating_type: 'hard'

# BlobNet
use_compressed_info: false

# Similarity Module:
# e.g., 'headwise-cosine^2', 'cosine^1', 'l2', 'sad'
similarity_type: 'sad'

# Importance Module:
# e.g., 'cls^1', 'zerotprune', 'none'
importance_type: 'none'

# Restoration Module:
restoration_type: 'passthrough'

reuse_start: 'before_qkv'

reference_type: 'first_only'